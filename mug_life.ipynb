{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### \\#MugLife"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6eeca1d9528e7fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 0 : : Set up"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99b58d39f21a950f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from client import client\n",
    "import pre_processing\n",
    "import utils\n",
    "import visualiser\n",
    "import method\n",
    "\n",
    "from praw.models import MoreComments\n",
    "\n",
    "import string\n",
    "\n",
    "import nltk \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "%nltk.download('vader_lexicon')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis.lda_model\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d536d6c40ffe65a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokeniser = TweetTokenizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "# add punctuation to stopwords list\n",
    "stop_words = stopwords.words('english') + list(string.punctuation) + ['rt', 'via', '...', '…', '\"', \"'\", '`', '-', '..']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c661a6147ac4bee0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "collected_posts = []\n",
    "unprocessed_token_lists = []\n",
    "processed_token_lists = []\n",
    "\n",
    "posts_df = pd.DataFrame(columns=['social_media_id', 'title', 'utc_date', 'formatted_date', 'desc', 'author', 'rating','num_comments', 'unprocessed_tokens', 'processed_tokens'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76076a2f3e72c9a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "social_media_id = os.environ[\"SOCIAL-MEDIA-ID\"]\n",
    "social_media_id = social_media_id.lower()\n",
    "\n",
    "collect_data_env = os.environ[\"COLLECT-DATA\"]  \n",
    "\n",
    "data_folder_path = os.environ[\"DATA-FOLDER-PATH\"]\n",
    "\n",
    "collect_data = True if collect_data_env == \"True\" else False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9e97c1b6eeafe85",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 1 : : Data collection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f3209c53ab1a51"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data collection from Reddit\n",
    "data_sample_filepath = f'{data_folder_path}/data.csv'\n",
    "\n",
    "if collect_data:\n",
    "    if social_media_id == 'reddit':\n",
    "        subreddit_names = 'tea+coffee+TeaPorn+pourover'\n",
    "        \n",
    "        reddit_client = client()\n",
    "        subreddit = reddit_client.subreddit(subreddit_names)\n",
    "        collected_posts = [*subreddit.top(limit=None)] \n",
    "        \n",
    "    reply_graph_filepath = f'{data_folder_path}/{social_media_id}_reply_graph.graphml'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b8a23928d30be08",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 2 : : Pre-processing and Exploration\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4542f44696aff292"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;197;145;3m\n",
      "\n",
      "------------------------------------\n",
      "Initial text\n",
      "\"If tea spread to your country by sea, you call it ‘tea’. If by land, you call it chai. (*This is because the ports of Fujian and Taiwan use the coastal pronunciation ‘te’, whereas Mandarin uses chá.)\" \n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "\u001B[38;2;175;34;29m\n",
      "\n",
      "------------------------------------\n",
      "Lowercase text\n",
      "\n",
      "------------------------------------\n",
      "\"if tea spread to your country by sea, you call it ‘tea’. if by land, you call it chai. (*this is because the ports of fujian and taiwan use the coastal pronunciation ‘te’, whereas mandarin uses chá.)\" \n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\u001B[38;2;175;34;29m\n",
      "\n",
      "------------------------------------\n",
      "Inverted comma removed text\n",
      "\n",
      "------------------------------------\n",
      "\"if tea spread to your country by sea, you call it tea. if by land, you call it chai. (*this is because the ports of fujian and taiwan use the coastal pronunciation te, whereas mandarin uses chá.)\" \n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\u001B[38;2;175;34;29m\n",
      "\n",
      "------------------------------------\n",
      "Emoji removed text\n",
      "\n",
      "------------------------------------\n",
      "\"if tea spread to your country by sea, you call it tea. if by land, you call it chai. (*this is because the ports of fujian and taiwan use the coastal pronunciation te, whereas mandarin uses chá.)\" \n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\u001B[38;2;175;34;29m\n",
      "\n",
      "------------------------------------\n",
      "Tags, mentions and links removed text\n",
      "\n",
      "------------------------------------\n",
      "\"if tea spread to your country by sea, you call it tea. if by land, you call it chai. (*this is because the ports of fujian and taiwan use the coastal pronunciation te, whereas mandarin uses chá.)\" \n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\u001B[38;2;175;34;29m\n",
      "\n",
      "------------------------------------\n",
      "Tokenized text\n",
      "\n",
      "------------------------------------\n",
      "['\"', 'if', 'tea', 'spread', 'to', 'your', 'country', 'by', 'sea', ',', 'you', 'call', 'it', 'tea', '.', 'if', 'by', 'land', ',', 'you', 'call', 'it', 'chai', '.', '(', '*', 'this', 'is', 'because', 'the', 'ports', 'of', 'fujian', 'and', 'taiwan', 'use', 'the', 'coastal', 'pronunciation', 'te', ',', 'whereas', 'mandarin', 'uses', 'chá', '.', ')', '\"']\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\u001B[38;2;175;34;29m\n",
      "\n",
      "------------------------------------\n",
      "Whitespace stripped tokenized text\n",
      "\n",
      "------------------------------------\n",
      "['\"', 'if', 'tea', 'spread', 'to', 'your', 'country', 'by', 'sea', ',', 'you', 'call', 'it', 'tea', '.', 'if', 'by', 'land', ',', 'you', 'call', 'it', 'chai', '.', '(', '*', 'this', 'is', 'because', 'the', 'ports', 'of', 'fujian', 'and', 'taiwan', 'use', 'the', 'coastal', 'pronunciation', 'te', ',', 'whereas', 'mandarin', 'uses', 'chá', '.', ')', '\"']\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\u001B[38;2;175;34;29m\n",
      "\n",
      "------------------------------------\n",
      "Digits removed tokenized text\n",
      "\n",
      "------------------------------------\n",
      "['\"', 'if', 'tea', 'spread', 'to', 'your', 'country', 'by', 'sea', ',', 'you', 'call', 'it', 'tea', '.', 'if', 'by', 'land', ',', 'you', 'call', 'it', 'chai', '.', '(', '*', 'this', 'is', 'because', 'the', 'ports', 'of', 'fujian', 'and', 'taiwan', 'use', 'the', 'coastal', 'pronunciation', 'te', ',', 'whereas', 'mandarin', 'uses', 'chá', '.', ')', '\"']\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\u001B[38;2;175;34;29m\n",
      "\n",
      "------------------------------------\n",
      "Stop words removed tokenized text\n",
      "\n",
      "------------------------------------\n",
      "['tea', 'spread', 'country', 'sea', 'call', 'tea', 'land', 'call', 'chai', 'ports', 'fujian', 'taiwan', 'use', 'coastal', 'pronunciation', 'te', 'whereas', 'mandarin', 'uses', 'chá']\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\u001B[38;2;39;92;77m\n",
      "\n",
      "------------------------------------\n",
      "Final tokenized text\n",
      "\n",
      "------------------------------------\n",
      "['tea', 'spread', 'country', 'sea', 'call', 'tea', 'land', 'call', 'chai', 'ports', 'fujian', 'taiwan', 'use', 'coastal', 'pronunciation', 'te', 'whereas', 'mandarin', 'uses', 'chá']\n",
      "\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Add the post id and the author to list of ids  \u001B[39;00m\n\u001B[1;32m     30\u001B[0m post_comment_ids[post_id] \u001B[38;5;241m=\u001B[39m {post_id: post_author}\n\u001B[0;32m---> 32\u001B[0m \u001B[43mpost\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcomments\u001B[49m\u001B[38;5;241m.\u001B[39mreplace_more(limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m comment \u001B[38;5;129;01min\u001B[39;00m post\u001B[38;5;241m.\u001B[39mcomments:\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(comment, MoreComments):\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/praw/models/reddit/base.py:35\u001B[0m, in \u001B[0;36mRedditBase.__getattr__\u001B[0;34m(self, attribute)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the value of ``attribute``.\"\"\"\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m attribute\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetched:\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, attribute)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattribute\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     39\u001B[0m )\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/praw/models/reddit/submission.py:712\u001B[0m, in \u001B[0;36mSubmission._fetch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    711\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_fetch\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 712\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fetch_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m     submission_listing, comment_listing \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    714\u001B[0m     comment_listing \u001B[38;5;241m=\u001B[39m Listing(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reddit, _data\u001B[38;5;241m=\u001B[39mcomment_listing[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/praw/models/reddit/submission.py:731\u001B[0m, in \u001B[0;36mSubmission._fetch_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    729\u001B[0m params\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_additional_fetch_params\u001B[38;5;241m.\u001B[39mcopy())\n\u001B[1;32m    730\u001B[0m path \u001B[38;5;241m=\u001B[39m API_PATH[name]\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfields)\n\u001B[0;32m--> 731\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reddit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/praw/util/deprecate_args.py:43\u001B[0m, in \u001B[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m     arg_string \u001B[38;5;241m=\u001B[39m _generate_arg_string(_old_args[: \u001B[38;5;28mlen\u001B[39m(args)])\n\u001B[1;32m     37\u001B[0m     warn(\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPositional arguments for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m will no longer be\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m supported in PRAW 8.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mCall this function with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marg_string\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     40\u001B[0m         \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m,\n\u001B[1;32m     41\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     42\u001B[0m     )\n\u001B[0;32m---> 43\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_old_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/praw/reddit.py:941\u001B[0m, in \u001B[0;36mReddit.request\u001B[0;34m(self, data, files, json, method, params, path)\u001B[0m\n\u001B[1;32m    939\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ClientException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAt most one of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    940\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 941\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_core\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    942\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    946\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    947\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    948\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    949\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m BadRequest \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[1;32m    950\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/prawcore/sessions.py:328\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, path, data, files, json, params, timeout)\u001B[0m\n\u001B[1;32m    326\u001B[0m     json[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapi_type\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    327\u001B[0m url \u001B[38;5;241m=\u001B[39m urljoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_requestor\u001B[38;5;241m.\u001B[39moauth_url, path)\n\u001B[0;32m--> 328\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request_with_retries\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/prawcore/sessions.py:234\u001B[0m, in \u001B[0;36mSession._request_with_retries\u001B[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001B[0m\n\u001B[1;32m    232\u001B[0m retry_strategy_state\u001B[38;5;241m.\u001B[39msleep()\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_request(data, method, params, url)\n\u001B[0;32m--> 234\u001B[0m response, saved_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry_strategy_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    245\u001B[0m do_retry \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m codes[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munauthorized\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/prawcore/sessions.py:186\u001B[0m, in \u001B[0;36mSession._make_request\u001B[0;34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_make_request\u001B[39m(\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    176\u001B[0m     data: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mtuple\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    183\u001B[0m     url: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m    184\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[Response, \u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mtuple\u001B[39m[\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m]:\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 186\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_rate_limiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_requestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_header_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m            \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m            \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m            \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m         log\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[1;32m    199\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mResponse: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m bytes) (rst-\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:rem-\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:used-\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m ratelimit) at \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    200\u001B[0m             response\u001B[38;5;241m.\u001B[39mstatus_code,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    205\u001B[0m             time\u001B[38;5;241m.\u001B[39mtime(),\n\u001B[1;32m    206\u001B[0m         )\n\u001B[1;32m    207\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response, \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/prawcore/rate_limit.py:47\u001B[0m, in \u001B[0;36mRateLimiter.call\u001B[0;34m(self, request_function, set_header_callback, *args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelay()\n\u001B[1;32m     46\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m set_header_callback()\n\u001B[0;32m---> 47\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrequest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate(response\u001B[38;5;241m.\u001B[39mheaders)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/prawcore/requestor.py:68\u001B[0m, in \u001B[0;36mRequestor.request\u001B[0;34m(self, timeout, *args, **kwargs)\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Issue the HTTP request capturing any errors that may occur.\"\"\"\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_http\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:  \u001B[38;5;66;03m# noqa: BLE001\u001B[39;00m\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RequestException(exc, args, kwargs) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/requests/adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    786\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    788\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 789\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[1;32m    805\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 536\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m~/Documents/Honours/SMNA/MugLife/venv/lib/python3.12/site-packages/urllib3/connection.py:507\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mresponse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPResponse\n\u001B[1;32m    506\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[0;32m--> 507\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    510\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/http/client.py:1428\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1427\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1428\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1429\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1430\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/http/client.py:331\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 331\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    332\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    333\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/http/client.py:292\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 292\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/socket.py:720\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    718\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    719\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 720\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    721\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    722\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/ssl.py:1252\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1249\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1250\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1251\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1252\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1253\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/ssl.py:1104\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1102\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1104\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1105\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1106\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Create dataframe containing reddit post details, unprocessed and pre-processed token lists\n",
    "# This bit extracts the data from reddit and saves it to the data file \n",
    "if collect_data:\n",
    "    reply_graph = nx.DiGraph()\n",
    "    # track the ids of post and comments for the reply graph\n",
    "    post_comment_ids = dict()\n",
    "\n",
    "    for post in collected_posts:\n",
    "        post_id = post.name\n",
    "\n",
    "        post_title = post.title\n",
    "        post_description = post.selftext\n",
    "        post_title_description = post_title + \" \" + post_description\n",
    "        post_date = pd.to_datetime(datetime.fromtimestamp(post.created_utc).strftime(\"%d/%m/%Y\"), format=\"%d/%m/%Y\")\n",
    "\n",
    "        unprocessed_tokens = tokeniser.tokenize(post_title_description)\n",
    "        unprocessed_token_lists.append(unprocessed_tokens)\n",
    "\n",
    "        processed_tokens = pre_processing.process(post_title_description, tokeniser, stemmer, stop_words, True)\n",
    "        # text, tokeniser, stop_words\n",
    "        processed_token_lists.append(processed_tokens)\n",
    "\n",
    "        if post.author is None:\n",
    "            post_author = 'None'\n",
    "        else:\n",
    "            post_author = post.author.name\n",
    "\n",
    "        reply_graph = method.update_reply_graph_node(reply_graph, post_author)\n",
    "        # Add the post id and the author to list of ids  \n",
    "        post_comment_ids[post_id] = {post_id: post_author}\n",
    "\n",
    "        post.comments.replace_more(limit=None)\n",
    "        for comment in post.comments:\n",
    "            if isinstance(comment, MoreComments):\n",
    "                continue\n",
    "\n",
    "            comment_text = comment.body if comment.body is None else ''\n",
    "\n",
    "            unprocessed_comment_tokens = tokeniser.tokenize(comment_text)\n",
    "            unprocessed_tokens = unprocessed_tokens + unprocessed_comment_tokens\n",
    "            unprocessed_token_lists.append(unprocessed_comment_tokens)\n",
    "\n",
    "            processed_comment_tokens = pre_processing.process(comment_text, tokeniser, stemmer, stop_words, False)\n",
    "            processed_tokens = processed_tokens + processed_comment_tokens\n",
    "            processed_token_lists.append(processed_comment_tokens)\n",
    "\n",
    "            # Check if comment author exists\n",
    "            comment_name = comment.name\n",
    "            comment_author = comment.author\n",
    "            if comment_author is not None and comment_author.name != 'ExternalUserError':\n",
    "                comment_author_name = comment_author.name\n",
    "\n",
    "                # Link the comment and comment author to the post id\n",
    "                post_comment_ids[post_id].update({comment_name: comment_author_name})\n",
    "\n",
    "                # Check whether parent comment is in the ids list  \n",
    "                # If not, then parent comment has been deleted\n",
    "                comment_parent_id = comment.parent_id\n",
    "                if comment_parent_id in post_comment_ids[post_id]:\n",
    "                    reply_graph = method.update_reply_graph_edge(reply_graph, comment_author_name, post_comment_ids,\n",
    "                                                                 post_id, comment_parent_id)\n",
    "\n",
    "        posts_df.loc[len(posts_df.index)] = [social_media_id, post_title, post.created_utc, post_date, post_description,\n",
    "                                             post_author, post.upvote_ratio, post.num_comments, unprocessed_tokens,\n",
    "                                             processed_tokens]\n",
    "        \n",
    "    # Save reply graph\n",
    "    nx.readwrite.write_graphml(reply_graph, reply_graph_filepath)\n",
    "    # Read old data file if it exists to append new data collected, if not save new file\n",
    "    old_posts_df = pd.DataFrame(\n",
    "        columns=['social_media_id', 'title', 'utc_date', 'formatted_date', 'desc', 'author', 'rating', 'num_comments',\n",
    "                 'unprocessed_tokens', 'processed_tokens'])\n",
    "\n",
    "    if os.path.isfile(data_sample_filepath):\n",
    "        old_posts_df = pd.read_csv(data_sample_filepath, header=0)\n",
    "\n",
    "        posts_df = pd.concat([old_posts_df, posts_df], ignore_index=True)\n",
    "\n",
    "    posts_df.to_csv(data_sample_filepath, index=False, header=True)\n",
    "\n",
    "len(posts_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aa8b2adcad14d37",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "if not collect_data: \n",
    "    posts_df = pd.read_csv(data_sample_filepath)\n",
    "    unprocessed_token_lists = posts_df.unprocessed_tokens.apply(lambda s: list(ast.literal_eval(s)))\n",
    "    posts_df['unprocessed_tokens'] = unprocessed_token_lists\n",
    "    processed_token_lists = posts_df.processed_tokens.apply(lambda s: list(ast.literal_eval(s)))\n",
    "    posts_df['processed_tokens'] = processed_token_lists\n",
    "    \n",
    "    posts_df['formatted_date'] = pd.to_datetime(posts_df['formatted_date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "posts_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4f795135f0ac1ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_num_posts = len(posts_df)\n",
    "print(f'Total number of posts: {total_num_posts}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7a04907dd8dea82",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_num_comments = posts_df['num_comments'].sum()\n",
    "print(f'Total number of comments: {total_num_comments}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1bd57e90959306",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_data_items = total_num_posts + total_num_comments\n",
    "print(f'Total data items: {total_data_items}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e12156a65e2353f7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_social_medias = posts_df['social_media_id'].unique()\n",
    "print(f'Social media data was collected from:\\n{df_social_medias}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97607f2fff1513e3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "flatted_unprocessed_token_list = [element for innerList in unprocessed_token_lists for element in innerList]   \n",
    "\n",
    "visualiser.compute_term_freq(flatted_unprocessed_token_list, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bea5ce626441af0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "processed_token_lists = [element for innerList in processed_token_lists for element in innerList]   \n",
    "\n",
    "visualiser.compute_term_freq(processed_token_lists, True, utils.red)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8580700a552f450",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 3 : : Method\n",
    "\n",
    "Methods explored:\n",
    "1. N-grams were explored to gain preliminary understanding of the sentiments in this subreddit\n",
    "2. Sentiment analysis via N-grams, Count and Vader techniques \n",
    "3. Topic modelling via LDA topic model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddfdc8bad9f00902"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# N-grams\n",
    "top_50_bi_grams =  nltk.collocations.BigramCollocationFinder.from_words(processed_token_lists).ngram_fd.most_common(50)\n",
    "top_50_tri_grams = nltk.collocations.TrigramCollocationFinder.from_words(processed_token_lists).ngram_fd.most_common(50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5572104d860fb4d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "count_sentiment_list = method.sentiment_analysis('Count', posts_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7702fa822a203e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vader_sentiment_list = method.sentiment_analysis('Vader', posts_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "782a78100108105a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Topic modelling\n",
    "num_topic = 10\n",
    "num_features = 1500\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=num_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(processed_token_lists)\n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topic, max_iter=10, learning_method='online').fit(tf)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8aac3e8b39186f7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Graphs and networks => Egonet\n",
    "\n",
    "# get the top author/s from the posts \n",
    "posts_df_by_rating = posts_df.sort_values(['rating', 'num_comments'], ascending=[False, False])\n",
    "posts_df_by_rating_filtered = posts_df_by_rating[posts_df_by_rating['author'] != 'None']\n",
    "subset_top_rated_authors_df = posts_df_by_rating_filtered.head(1)\n",
    "\n",
    "print('------------Ego graph exploration------------\\n')\n",
    "ego_graph_list = []\n",
    "for row in subset_top_rated_authors_df.itertuples():\n",
    "    author_name = row.author   \n",
    "    row_social_media_id = row.social_media_id\n",
    "    \n",
    "    print(utils.yellow_rgb + f'Social media id: {social_media_id}\\n', end='')\n",
    "    print(utils.yellow_rgb + f'Author name: {author_name}\\nAuthor rating: {row.rating}\\nAuthor comments: {row.num_comments}\\n', end='')\n",
    "    \n",
    "    if row_social_media_id == 'reddit':\n",
    "        if not collect_data:\n",
    "            reddit_client = client()\n",
    "        ego = reddit_client.redditor(author_name)\n",
    "        ego_name = ego.name\n",
    "        ego_graph = method.construct_ego_graph(reddit_client, ego, ego_name)\n",
    "        ego_graph_list.append({'ego_graph': ego_graph, 'ego_name': ego_name})\n",
    "        \n",
    "        # Note: print_ego_graph does not depend on the social media used\n",
    "        utils.print_ego_graph(data_folder_path, ego_graph, ego_name)\n",
    "        \n",
    "subset_top_rated_authors_df  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45a3f234fc005b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Reply graph\n",
    "if 'reddit' in df_social_medias:\n",
    "    reply_graph_filepath = f'{data_folder_path}/{social_media_id}_reply_graph.graphml'\n",
    "    reply_graph = nx.readwrite.read_graphml(reply_graph_filepath)\n",
    "\n",
    "    degree_centrality_list = nx.degree_centrality(reply_graph)\n",
    "    eigen_vector_centrality_list = nx.eigenvector_centrality(reply_graph)\n",
    "    katz_centrality_list = nx.katz_centrality(reply_graph)\n",
    "\n",
    "    visualiser.display_centrality_histograms(degree_centrality_list, eigen_vector_centrality_list, katz_centrality_list)\n",
    "\n",
    "    # Update node attributes with centrality\n",
    "    # eigenvector centrality, stored in node attribute 'eigen'\n",
    "    for nodeId, cent in eigen_vector_centrality_list.items():\n",
    "        reply_graph.nodes[nodeId]['eigen'] = float(cent)\n",
    "\n",
    "    # katz centrality, stored in node attribute 'katz'\n",
    "    for nodeId, cent in katz_centrality_list.items():\n",
    "        reply_graph.nodes[nodeId]['katz'] = float(cent)\n",
    "\n",
    "    modified_reply_graph_filepath = f'{data_folder_path}/{social_media_id}_modified_reply_graph.graphml'\n",
    "    nx.readwrite.write_graphml(reply_graph, modified_reply_graph_filepath, infer_numeric_types=True)\n",
    "\n",
    "    # compute clustering\n",
    "    print(utils.yellow_rgb + f'\\n\\nGlobal clustering coefficient/transitivity: {nx.transitivity(reply_graph)}', end='')\n",
    "\n",
    "    # compute components\n",
    "    print(\n",
    "        utils.green_rgb + f'\\n\\nNumber of strongly connected components: {nx.number_strongly_connected_components(reply_graph)}',\n",
    "        end='')\n",
    "    print(\n",
    "        utils.red_rgb + f'\\n\\nNumber of weakly connected components: {nx.number_weakly_connected_components(reply_graph)}',\n",
    "        end='')\n",
    "    print(utils.yellow_rgb + f'\\n\\nBridges:\\n{list(nx.bridges(reply_graph.to_undirected()))}', end='')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82146a5db285996f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 4 : : Analysis\n",
    "\n",
    "Questions to explore:\n",
    "1. Which is the superior beverage?\n",
    "2. What are the most talked topics?\n",
    "3. Which parts of the world favour which bev? What are their feelings and opinions?\n",
    "4. Since we're in Melbourne, maybe a special look into Melbourne?\n",
    "5. Spike in engagement of people with sales and deals; limited time events, world tea/coffee days, variation of engagement with change of season -- Event and correlations \n",
    "6. Origin of tea/ coffee\n",
    "7. Benefits people get from tea/ coffee"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c331e1ed2ad759f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# n-grams\n",
    "top_50_bi_grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d32b34150867ed64",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "top_50_tri_grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e1e4ab6b2852da1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Posts per date\n",
    "num_posts_per_date = posts_df.groupby('formatted_date')['title'].count()\n",
    "visualiser.display_time_series_stats(num_posts_per_date, 'count', 'Number of posts per date', 'Dates', 'Number of posts', utils.red)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c20d18e25d32f6d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Posts per author\n",
    "# Displaying authors with only more than 1 post\n",
    "num_posts_per_author = posts_df.groupby('author')['title'].count()\n",
    "\n",
    "num_posts_per_author_ordered = num_posts_per_author.reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "print(f'Posts per author:\\n{num_posts_per_author_ordered.head()}')\n",
    "\n",
    "filtered_df = num_posts_per_author_ordered[num_posts_per_author_ordered['count'] > 5 ]\n",
    "filtered_df = filtered_df[filtered_df['author'] != 'None']\n",
    "\n",
    "num_posts_per_author_y = filtered_df['count']\n",
    "author_x = filtered_df['author']\n",
    "visualiser.generate_bar_chart(author_x, num_posts_per_author_y, utils.red, 'Number of posts per author', 'Author', 'Number of posts')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4147e8a33105eba8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "# Count\n",
    "visualiser.generate_time_series(count_sentiment_list, 'Sentiment based on count', 'date', 'sentiment', 'Date', 'Count sentiment', utils.green)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b17a7d2b10085ab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Vader\n",
    "visualiser.generate_time_series(vader_sentiment_list, 'Sentiment based on vader', 'date', 'sentiment', 'Date', 'Veder sentiment', utils.green)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc3cbe97170db62d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Topic modelling\n",
    "max_word_count_to_display = 15\n",
    "visualiser.display_topics(lda_model, tf_feature_names, max_word_count_to_display)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab40ed9fbbefbca5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pyLDAvis\n",
    "panel = pyLDAvis.lda_model.prepare(lda_model, tf, tf_vectorizer, mds='tsne')\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(panel)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d11932142bd1fc3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# wordcloud\n",
    "visualiser.display_word_cloud(lda_model, tf_feature_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5fe75b215f13209",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Display the ego graphs for the top users\n",
    "\n",
    "for item in ego_graph_list:\n",
    "    ego_graph = item.get('ego_graph')\n",
    "    ego_name = item.get('ego_name')\n",
    "    print(f'Ego name: {ego_name}\\n\\n')\n",
    "    visualiser.display_networkx_graph(ego_graph, f'Ego graph for {ego_name}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "292a1646c4199682",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Display reply graph\n",
    "\n",
    "if 'reddit' in df_social_medias:\n",
    "    reply_graph_filepath = f'{data_folder_path}/{social_media_id}_reply_graph.graphml'\n",
    "    reply_graph = nx.readwrite.read_graphml(reply_graph_filepath)\n",
    "    visualiser.display_networkx_graph(reply_graph, 'Reddit reply graph')\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efd6610380ddfccb",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
