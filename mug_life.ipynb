{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### \\#MugLife"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6eeca1d9528e7fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 0 : : Set up"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99b58d39f21a950f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "from client import client\n",
    "import utils\n",
    "import visualiser\n",
    "import method\n",
    "import pre_processing\n",
    "\n",
    "import nltk \n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis.lda_model\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import plotly.express as px\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "install(\"python-louvain\")\n",
    "load_dotenv()\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d536d6c40ffe65a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f'Process start: {datetime.now()}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5b519b681468f40",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# All posts\n",
    "collected_posts = []\n",
    "\n",
    "tea_unprocessed_token_lists = []\n",
    "tea_processed_token_lists = []\n",
    "\n",
    "coffee_unprocessed_token_lists = []\n",
    "coffee_processed_token_lists = []\n",
    "\n",
    "tea = 'tea'\n",
    "coffee = 'coffee'\n",
    "num_beverages = 2\n",
    "\n",
    "posts_df = pd.DataFrame(columns=['social_media_id', 'post_type', 'title', 'utc_date', 'formatted_date', 'desc', 'author', 'rating','num_comments', 'unprocessed_tokens', 'processed_tokens'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76076a2f3e72c9a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "social_media_id = os.environ[\"SOCIAL-MEDIA-ID\"]\n",
    "social_media_id = social_media_id.lower()\n",
    "\n",
    "collect_data_env = os.environ[\"COLLECT-DATA\"]  \n",
    "data_limit = os.environ[\"DATA-LIMIT\"]\n",
    "\n",
    "data_collection_limit = None\n",
    "if data_limit != 'None':\n",
    "    data_collection_limit =  int(data_limit)\n",
    "data_folder_path = os.environ[\"DATA-FOLDER-PATH\"]\n",
    "\n",
    "collect_data = True if collect_data_env == \"True\" else False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9e97c1b6eeafe85",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 1 : : Data collection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f3209c53ab1a51"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data collection from Reddit\n",
    "data_sample_filepath = f'{data_folder_path}/data.csv'\n",
    "\n",
    "if collect_data:\n",
    "    if social_media_id == 'reddit':\n",
    "        subreddit_names = 'tea+coffee+TeaPorn+pourover'\n",
    "        \n",
    "        reddit_client = client()\n",
    "        subreddit = reddit_client.subreddit(subreddit_names)\n",
    "        collected_posts = [*subreddit.top(limit=data_collection_limit)] "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b8a23928d30be08",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 2 : : Pre-processing and Exploration\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4542f44696aff292"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create dataframe containing reddit post details, unprocessed and pre-processed token lists\n",
    "# This bit extracts the data from reddit and saves it to the data file \n",
    "if collect_data:\n",
    "    if social_media_id == 'reddit':\n",
    "        tea_unprocessed_token_lists, coffee_unprocessed_token_lists, tea_processed_token_lists, coffee_processed_token_lists, posts_df = pre_processing.reddit_data_collection( \n",
    "        data_folder_path, collected_posts, data_sample_filepath)\n",
    "    \n",
    "len(posts_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aa8b2adcad14d37",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "if not collect_data: \n",
    "    posts_df = pd.read_csv(data_sample_filepath)\n",
    "    tea_unprocessed_token_lists = posts_df[posts_df['post_type'] == tea].unprocessed_tokens.apply(lambda s: list(ast.literal_eval(s)))\n",
    "    posts_df[posts_df['post_type'] == tea]['unprocessed_tokens'] = tea_unprocessed_token_lists\n",
    "    tea_unprocessed_token_lists = list(tea_unprocessed_token_lists)\n",
    "    \n",
    "    coffee_unprocessed_token_lists = posts_df[posts_df['post_type'] == coffee].unprocessed_tokens.apply(lambda s: list(ast.literal_eval(s)))\n",
    "    posts_df[posts_df['post_type'] == coffee]['unprocessed_tokens'] = coffee_unprocessed_token_lists\n",
    "    coffee_unprocessed_token_lists = list(coffee_unprocessed_token_lists)\n",
    "    \n",
    "    tea_processed_token_lists = posts_df[posts_df['post_type'] == tea].processed_tokens.apply(lambda s: list(ast.literal_eval(s)))\n",
    "    posts_df[posts_df['post_type'] == tea]['processed_tokens'] = tea_processed_token_lists\n",
    "    tea_processed_token_lists = list(tea_processed_token_lists)\n",
    "    \n",
    "    coffee_processed_token_lists = posts_df[posts_df['post_type'] == coffee].processed_tokens.apply(lambda s: list(ast.literal_eval(s)))\n",
    "    posts_df[posts_df['post_type'] == coffee]['processed_tokens'] = coffee_processed_token_lists\n",
    "    coffee_processed_token_lists = list(coffee_processed_token_lists)\n",
    "    \n",
    "    posts_df['formatted_date'] = pd.to_datetime(posts_df['formatted_date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "posts_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4f795135f0ac1ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_num_posts = len(posts_df)\n",
    "print(f'Total number of posts: {total_num_posts}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7a04907dd8dea82",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_num_comments = posts_df['num_comments'].sum()\n",
    "print(f'Total number of comments: {total_num_comments}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1bd57e90959306",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_data_items = total_num_posts + total_num_comments\n",
    "print(f'Total data items: {total_data_items}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e12156a65e2353f7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tea_df = posts_df[posts_df['post_type'] == tea]\n",
    "\n",
    "tea_df_count = len(tea_df)\n",
    "\n",
    "print(f'Total tea posts: {tea_df_count}')\n",
    "\n",
    "tea_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b98c69fcc5adeac8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_df = posts_df[posts_df['post_type'] == coffee]\n",
    "\n",
    "coffee_df_count = len(coffee_df)\n",
    "\n",
    "print(f'Total coffee posts: {coffee_df_count}')\n",
    "\n",
    "coffee_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a62af45be7fc4233",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_social_medias = posts_df['social_media_id'].unique()\n",
    "print(f'Social media data was collected from:\\n{df_social_medias}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97607f2fff1513e3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tea_unprocessed_token_lists"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca4b84523e8e756",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tea_processed_token_lists"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dded75cfa6c19513",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_unprocessed_token_lists"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63dbc7130ec4fabc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_processed_token_lists"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42747e325872607",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tea_flatted_unprocessed_token_list = [element for innerList in tea_unprocessed_token_lists for element in innerList]   \n",
    "\n",
    "coffee_flatted_unprocessed_token_list = [element for innerList in coffee_unprocessed_token_lists for element in innerList]   \n",
    "\n",
    "visualiser.compute_term_freq(tea, tea_flatted_unprocessed_token_list, True)\n",
    "visualiser.compute_term_freq(coffee, coffee_flatted_unprocessed_token_list, True, utils.red)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bea5ce626441af0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tea_processed_token_lists = [element for innerList in tea_processed_token_lists for element in innerList]   \n",
    "coffee_processed_token_lists = [element for innerList in coffee_processed_token_lists for element in innerList]   \n",
    "\n",
    "visualiser.compute_term_freq(tea, tea_processed_token_lists, True)\n",
    "visualiser.compute_term_freq(coffee, coffee_processed_token_lists, True, utils.red)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8580700a552f450",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 3 : : Method\n",
    "\n",
    "Methods explored:\n",
    "1. N-grams were explored to gain preliminary understanding of the sentiments in this subreddit\n",
    "2. Sentiment analysis via N-grams, Count and Vader techniques \n",
    "3. Topic modelling via LDA topic model\n",
    "4. Ego-graph\n",
    "5. Reply graph\n",
    "6. Community detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddfdc8bad9f00902"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# N-grams\n",
    "\n",
    "# Tea\n",
    "tea_top_50_bi_grams =  nltk.collocations.BigramCollocationFinder.from_words(tea_processed_token_lists).ngram_fd.most_common(50)\n",
    "tea_top_50_tri_grams = nltk.collocations.TrigramCollocationFinder.from_words(tea_processed_token_lists).ngram_fd.most_common(50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5572104d860fb4d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Coffee\n",
    "coffee_top_50_bi_grams =  nltk.collocations.BigramCollocationFinder.from_words(coffee_processed_token_lists).ngram_fd.most_common(50)\n",
    "coffee_top_50_tri_grams = nltk.collocations.TrigramCollocationFinder.from_words(coffee_processed_token_lists).ngram_fd.most_common(50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d4621a97e595fd8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "tea_count_sentiment_list = method.sentiment_analysis('Count', tea_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7702fa822a203e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_count_sentiment_list = method.sentiment_analysis('Count', coffee_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "681a72a04208921f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tea_vader_sentiment_list = method.sentiment_analysis('Vader', tea_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "782a78100108105a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_vader_sentiment_list = method.sentiment_analysis('Vader', coffee_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a27d72a86e8ffc1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Topic modelling\n",
    "num_topic = 10\n",
    "num_features = 1500"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8aac3e8b39186f7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tea_tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=num_features, stop_words='english')\n",
    "\n",
    "tea_tf = tea_tf_vectorizer.fit_transform(tea_processed_token_lists)\n",
    "tea_tf_feature_names = tea_tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "tea_lda_model = LatentDirichletAllocation(n_components=num_topic, max_iter=10, learning_method='online').fit(tea_tf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5fc8f642a404c37",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=num_features, stop_words='english')\n",
    "\n",
    "coffee_tf = coffee_tf_vectorizer.fit_transform(coffee_processed_token_lists)\n",
    "\n",
    "coffee_tf_feature_names = coffee_tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "coffee_lda_model = LatentDirichletAllocation(n_components=num_topic, max_iter=10, learning_method='online').fit(coffee_tf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba74466923fe9bb3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Graphs and networks\n",
    "\n",
    "# Egonet\n",
    "# get the top author/s from the posts \n",
    "ego_graph_list = []\n",
    "for beverage_type_index in range(num_beverages):\n",
    "    beverage_df = tea_df\n",
    "    beverage_type = tea\n",
    "    if beverage_type_index == 1:\n",
    "        beverage_df = coffee_df\n",
    "        beverage_type = coffee\n",
    "        \n",
    "    beverage_df_by_rating = beverage_df.sort_values(['rating', 'num_comments'], ascending=[False, False])\n",
    "    beverage_df_by_rating_filtered = beverage_df_by_rating[beverage_df_by_rating['author'] != 'None']\n",
    "    subset_top_rated_authors_df = beverage_df_by_rating_filtered.head(1)\n",
    "    \n",
    "    print(f'------------Ego graph exploration for {beverage_type}------------\\n')\n",
    "    for row in subset_top_rated_authors_df.itertuples():\n",
    "        author_name = row.author   \n",
    "        row_social_media_id = row.social_media_id\n",
    "        \n",
    "        print(utils.yellow_rgb + f'Social media id: {social_media_id}\\n', end='')\n",
    "        print(utils.yellow_rgb + f'Author name: {author_name}\\nAuthor rating: {row.rating}\\nAuthor comments: {row.num_comments}\\n', end='')\n",
    "        \n",
    "        # if ego graph exists load from file else, create the graph\n",
    "        ego_graph_filepath = f'{data_folder_path}/{beverage_type}_ego_{author_name}.graphml'\n",
    "        if row_social_media_id == 'reddit':\n",
    "            if not collect_data:\n",
    "                reddit_client = client()\n",
    "            ego = reddit_client.redditor(author_name)\n",
    "            ego_name = ego.name\n",
    "            if os.path.isfile(ego_graph_filepath):\n",
    "                ego_graph = nx.readwrite.read_graphml(ego_graph_filepath)\n",
    "            else:\n",
    "                ego_graph = method.construct_ego_graph(reddit_client, ego, ego_name, ego_graph_filepath)\n",
    "            ego_graph_list.append({'ego_graph': ego_graph, 'ego_name': ego_name})\n",
    "        \n",
    "            # Note: print_ego_graph does not depend on the social media used\n",
    "            utils.print_ego_graph_stats(ego_graph, ego_name)  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45a3f234fc005b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Centrality of reply graphs\n",
    "if 'reddit' in df_social_medias:\n",
    "    tea_reddit_reply_graph_filepath = f'{data_folder_path}/reddit_tea_reply_graph.graphml'\n",
    "    tea_reddit_reply_graph = nx.readwrite.read_graphml(tea_reddit_reply_graph_filepath)\n",
    "    \n",
    "    coffee_reddit_reply_graph_filepath = f'{data_folder_path}/reddit_coffee_reply_graph.graphml'\n",
    "    coffee_reddit_reply_graph = nx.readwrite.read_graphml(coffee_reddit_reply_graph_filepath)\n",
    "    \n",
    "    # Reply graph\n",
    "    print('\\n------------Reply graph exploration------------\\n')\n",
    "    method.compute_reply_graph_stats(tea_reddit_reply_graph, data_folder_path, 'reddit', tea, utils.green)\n",
    "    method.compute_reply_graph_stats(coffee_reddit_reply_graph, data_folder_path, 'reddit', coffee, utils.red)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82146a5db285996f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Community detection\n",
    "if 'reddit' in df_social_medias:\n",
    "    \n",
    "    tea_reddit_reply_graph_filepath = f'{data_folder_path}/reddit_tea_reply_graph.graphml'\n",
    "    tea_reddit_reply_graph = nx.readwrite.read_graphml(tea_reddit_reply_graph_filepath)\n",
    "    \n",
    "    coffee_reddit_reply_graph_filepath = f'{data_folder_path}/reddit_coffee_reply_graph.graphml'\n",
    "    coffee_reddit_reply_graph = nx.readwrite.read_graphml(coffee_reddit_reply_graph_filepath)\n",
    "    \n",
    "    # Create community\n",
    "    print('\\n------------Community graph exploration------------\\n')\n",
    "    method.compute_community_stats(tea_reddit_reply_graph, data_folder_path, 'reddit', tea)\n",
    "    method.compute_community_stats(coffee_reddit_reply_graph, data_folder_path, 'reddit', coffee)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6252380de8db2ec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Linear threshold model for influence modelling\n",
    "seed_num = 3\n",
    "list_of_seeds = [0,1]\n",
    "trial_num = 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "820642abc8d7e236",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Explore reddit users' communities\n",
    "tea_authors_df = utils.get_author_df(tea, tea_df, reddit_client)\n",
    "\n",
    "tea_authors_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89f3011d0f5f09d1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_authors_df = utils.get_author_df(coffee, coffee_df, reddit_client)\n",
    "\n",
    "coffee_authors_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f09a635c9085b10",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 4 : : Analysis\n",
    "\n",
    "Questions to explore:\n",
    "1. Which is the superior beverage?\n",
    "2. What are the most talked topics?\n",
    "3. Which parts of the world favour which bev? What are their feelings and opinions?\n",
    "4. Since we're in Melbourne, maybe a special look into Melbourne?\n",
    "5. Spike in engagement of people with sales and deals; limited time events, world tea/coffee days, variation of engagement with change of season -- Event and correlations \n",
    "6. Origin of tea/ coffee\n",
    "7. Benefits people get from tea/ coffee"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c331e1ed2ad759f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# n-grams\n",
    "tea_top_50_bi_grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d32b34150867ed64",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tea_top_50_tri_grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e1e4ab6b2852da1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_top_50_bi_grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbe3a7439869a6fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_top_50_tri_grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1462342e8af33366",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Posts per date\n",
    "tea_num_posts_per_date = tea_df.groupby('formatted_date')['title'].count()\n",
    "coffee_num_posts_per_date = coffee_df.groupby('formatted_date')['title'].count()\n",
    "\n",
    "visualiser.display_time_series_stats(tea_num_posts_per_date, 'count', 'Number of posts per date for tea dataset', 'Dates', 'Number of posts', utils.green)\n",
    "visualiser.display_time_series_stats(coffee_num_posts_per_date, 'count', 'Number of posts per date for coffee dataset', 'Dates', 'Number of posts', utils.red)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c20d18e25d32f6d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Posts per author\n",
    "# Displaying authors with only more than 1 post\n",
    "def display_posts_per_author(df, beverage_type, graph_colour):\n",
    "    num_posts_per_author = df.groupby('author')['title'].count()\n",
    "    \n",
    "    num_posts_per_author_ordered = num_posts_per_author.reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "    print(f'Posts per author:\\n{num_posts_per_author_ordered.head()}')\n",
    "    \n",
    "    filtered_df = num_posts_per_author_ordered[num_posts_per_author_ordered['count'] > 5 ]\n",
    "    filtered_df = filtered_df[filtered_df['author'] != 'None']\n",
    "    \n",
    "    num_posts_per_author_y = filtered_df['count']\n",
    "    author_x = filtered_df['author']\n",
    "    visualiser.generate_bar_chart(author_x, num_posts_per_author_y, graph_colour, f'Number of posts per author for {beverage_type} dataset', 'Author', 'Number of posts')\n",
    "\n",
    "display_posts_per_author(tea_df, tea, utils.green)\n",
    "display_posts_per_author(coffee_df, coffee, utils.yellow)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4147e8a33105eba8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Author influence on other subreddits\n",
    "if not tea_authors_df.empty: visualiser.display_author_influence(tea_authors_df, tea)\n",
    "\n",
    "if not coffee_authors_df.empty: visualiser.display_author_influence(coffee_authors_df, coffee)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "749ab22a39a84e5f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tea and Coffee frequency by bean/leaf type \n",
    "\n",
    "unique_tea_leaves = ['black', 'green', 'white', 'yellow', 'oolong', 'dark']\n",
    "visualiser.generate_frequency_graph(unique_tea_leaves, tea_processed_token_lists, 'Leaf types', utils.green)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f229cee9a3c620e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unique_coffee_beans = ['arabica', 'robusta', 'excelsa', 'liberica']\n",
    "visualiser.generate_frequency_graph(unique_coffee_beans, coffee_processed_token_lists, 'Bean types', utils.yellow)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a72c5b18c4e821b5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tea and Coffee types\n",
    "unique_tea_styles = ['chai', 'thai', 'kashmiri', 'bubble', 'masala', 'milk', 'matcha', 'earl', 'ginger', 'pu', 'po', 'sweet', 'teh', 'cha', 'hojicha', 'yen', 'touareg']\n",
    "\n",
    "visualiser.generate_frequency_graph(unique_tea_styles, tea_processed_token_lists, 'Tea styles', utils.green)\n",
    "\n",
    "unique_coffee_styles = ['mocha', 'latte', 'long', 'double', 'short', 'espresso', 'macchiato', 'ristretto', 'cappuccino', 'irish', 'affogato', 'martini', 'decaf', 'americano', 'iced coffee']\n",
    "\n",
    "visualiser.generate_frequency_graph(unique_coffee_styles, coffee_processed_token_lists, 'Coffee styles', utils.yellow)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55b003c363dd0f4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tea and Coffee making styles\n",
    "unique_tea_brews = ['infusion', 'cold', 'gong', 'press']\n",
    "visualiser.generate_frequency_graph(unique_tea_brews, tea_processed_token_lists, 'Tea brews', utils.green)\n",
    "\n",
    "unique_coffee_brews = ['espresso', 'filter', 'press']\n",
    "visualiser.generate_frequency_graph(unique_coffee_brews, coffee_processed_token_lists, 'Coffee brews', utils.yellow)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffb35decbf5b1a71",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tea and Coffee frequency by origin\n",
    "\n",
    "tea_origin = ['china', 'india', 'kenya', 'lanka', 'ceylon', 'turkey', 'vietnam', 'indonesia', 'bangladesh', 'argentina', 'uganda']\n",
    "visualiser.generate_frequency_graph(tea_origin, tea_processed_token_lists, 'Tea origin', utils.green)\n",
    "\n",
    "coffee_origin = ['brazil', 'vietnam', 'indonesia', 'colombia', 'ethiopia', 'honduras', 'peru', 'india', 'kenya']\n",
    "visualiser.generate_frequency_graph(coffee_origin, coffee_processed_token_lists, 'Coffee origin', utils.yellow)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ac9fdbc9cfcff84",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "visualiser.create_world_map(tea_origin, tea_processed_token_lists, tea)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70bb0952d5dfe53b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "visualiser.create_world_map(coffee_origin, coffee_processed_token_lists, coffee)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83ab4529edae27ba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# popular countries \n",
    "all_countries = px.data.gapminder().query(\"year==2007\")['country']\n",
    "all_countries = [country.lower() for country in all_countries]\n",
    "all_countries.append('lanka')\n",
    "all_countries.append('ceylon')\n",
    "\n",
    "visualiser.create_world_map(all_countries, tea_processed_token_lists, 'all_tea')\n",
    "\n",
    "visualiser.create_world_map(all_countries, coffee_processed_token_lists, 'all_coffee')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8ac5266378acdc2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "# Count\n",
    "visualiser.generate_time_series(tea_count_sentiment_list, 'Sentiment based on count for tea dataset', 'date', 'sentiment', 'Date', 'Count sentiment', utils.green)\n",
    "\n",
    "visualiser.generate_time_series(coffee_count_sentiment_list, 'Sentiment based on count for coffee dataset', 'date', 'sentiment', 'Date', 'Count sentiment', utils.red)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b17a7d2b10085ab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Vader\n",
    "visualiser.generate_time_series(tea_vader_sentiment_list, 'Sentiment based on vader for tea dataset', 'date', 'sentiment', 'Date', 'Vader sentiment', utils.green)\n",
    "\n",
    "visualiser.generate_time_series(coffee_vader_sentiment_list, 'Sentiment based on vader for coffee dataset', 'date', 'sentiment', 'Date', 'Vader sentiment', utils.red)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc3cbe97170db62d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Topic modelling\n",
    "def display_topic_model(beverage_type_for_topic_modelling):\n",
    "    if beverage_type_for_topic_modelling == tea:\n",
    "        current_lda_model = tea_lda_model\n",
    "        current_tf_feature_names = tea_tf_feature_names\n",
    "        current_tf = tea_tf\n",
    "        current_tf_vectorizer = tea_tf_vectorizer\n",
    "    else:\n",
    "        current_lda_model = coffee_lda_model\n",
    "        current_tf_feature_names = coffee_tf_feature_names\n",
    "        current_tf = coffee_tf\n",
    "        current_tf_vectorizer = coffee_tf_vectorizer\n",
    "    \n",
    "    max_word_count_to_display = 15\n",
    "    visualiser.display_topics(current_lda_model, current_tf_feature_names, max_word_count_to_display)\n",
    "    \n",
    "    panel = pyLDAvis.lda_model.prepare(current_lda_model, current_tf, current_tf_vectorizer, mds='tsne')\n",
    "    pyLDAvis.enable_notebook()\n",
    "    return panel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab40ed9fbbefbca5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pyLDAvis\n",
    "tea_panel = display_topic_model(tea)\n",
    "pyLDAvis.display(tea_panel)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d11932142bd1fc3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coffee_panel = display_topic_model(coffee)\n",
    "pyLDAvis.display(coffee_panel)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6e9839b291dcac9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# wordcloud\n",
    "visualiser.display_word_cloud(tea_lda_model, tea_tf_feature_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5fe75b215f13209",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "visualiser.display_word_cloud(coffee_lda_model, coffee_tf_feature_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "380d2ba768b582ef",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Display the ego graphs for the top users\n",
    "\n",
    "for item in ego_graph_list:\n",
    "    ego_graph = item.get('ego_graph')\n",
    "    ego_name = item.get('ego_name')\n",
    "    print(f'Ego name: {ego_name}\\n\\n')\n",
    "    visualiser.display_networkx_graph(ego_graph, f'Ego graph for {ego_name}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "292a1646c4199682",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Author influence graph\n",
    "if not tea_authors_df.empty:\n",
    "    u_tea_authors = utils.get_unique_authors(tea_authors_df, tea)\n",
    "    visualiser.author_influence_graph(tea_authors_df, u_tea_authors)\n",
    "\n",
    "if not coffee_authors_df.empty:\n",
    "    u_coffee_authors = utils.get_unique_authors(coffee_authors_df, coffee)\n",
    "    visualiser.author_influence_graph(coffee_authors_df, u_coffee_authors)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2695201409aecc6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Reply graph types \n",
    "type_reply = 'reply'\n",
    "type_centrality = 'centrality'\n",
    "type_community = 'community'\n",
    "\n",
    "graph_types = [type_reply, type_centrality, type_community]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6aeab86be09fda11",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for graph_type in graph_types:\n",
    "    for beverage_type_index in range(num_beverages):\n",
    "        beverage_type = tea\n",
    "        if beverage_type_index == 1:\n",
    "            beverage_type = coffee\n",
    "\n",
    "        print(f'\\nBeverage type: {beverage_type}\\nGraph type: {graph_type}\\n')\n",
    "        prefix_filepath = f'{data_folder_path}/{social_media_id}_{beverage_type}_{graph_type}'\n",
    "\n",
    "        graph_filepath = f'{prefix_filepath}_graph.graphml'\n",
    "        loaded_graph = nx.readwrite.read_graphml(graph_filepath)\n",
    "\n",
    "        print('\\nTree graph\\n')\n",
    "        visualiser.display_tree_graph(trial_num, list_of_seeds, loaded_graph, prefix_filepath)\n",
    "\n",
    "        # print('\\nSmall world graph\\n')\n",
    "        # visualiser.display_barabasi_albert_graph(trial_num, list_of_seeds, loaded_graph, prefix_filepath)\n",
    "\n",
    "        print('\\nLinear threshold stats\\n')\n",
    "        visualiser.display_linear_threshold_stats(trial_num, list_of_seeds, loaded_graph, prefix_filepath)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfe2e2288a223495",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9fa8978de2671c7a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f'Process end: {datetime.now()}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9d158789e64faa",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
